{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalshi Market Calibration Analysis\n",
    "\n",
    "**Purpose**: Validate that Kalshi market prices are well-calibrated probability estimates.\n",
    "\n",
    "**Why This Matters**: A well-calibrated market means:\n",
    "- Events predicted at 70% actually happen ~70% of the time\n",
    "- Trading strategies can trust price signals\n",
    "- Edge exists through timing, not market inefficiency\n",
    "\n",
    "**Phase 1C Requirement**: Demonstrate calibration quality with reliability diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import utils\n",
    "from utils import get_engine, load_market_data\n",
    "from utils.visualization import plot_reliability_diagram\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "\n",
    "# Load all market snapshots\n",
    "df = load_market_data(engine, min_snapshots=10)\n",
    "\n",
    "print(f\"Loaded {len(df):,} snapshots\")\n",
    "print(f\"Unique tickers: {df['ticker'].nunique()}\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Resolved Markets\n",
    "\n",
    "**Challenge**: We need market outcomes to assess calibration.\n",
    "\n",
    "**Approach**:\n",
    "1. Find markets that stopped updating (likely resolved)\n",
    "2. Infer outcome from final price movement\n",
    "3. Validate calibration on resolved markets\n",
    "\n",
    "**Note**: This is a simplified approach. Production systems would use Kalshi's settlement API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find markets that haven't updated recently (likely resolved)\n",
    "now = datetime.now()\n",
    "ticker_last_update = df.groupby('ticker')['timestamp'].max()\n",
    "hours_since_update = (now - ticker_last_update).dt.total_seconds() / 3600\n",
    "\n",
    "# Consider markets resolved if no update in 2+ hours\n",
    "resolved_tickers = hours_since_update[hours_since_update > 2].index\n",
    "\n",
    "print(f\"Found {len(resolved_tickers)} potentially resolved markets\")\n",
    "print(f\"Sample tickers: {list(resolved_tickers[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For resolved markets, infer outcome from final price\n",
    "# If yes_prob > 0.9 at end, assume YES outcome (1)\n",
    "# If yes_prob < 0.1 at end, assume NO outcome (0)\n",
    "# Otherwise, exclude (ambiguous)\n",
    "\n",
    "def infer_outcome(ticker_df):\n",
    "    \"\"\"Infer market outcome from final price.\"\"\"\n",
    "    final_price = ticker_df.iloc[-1]['yes_prob']\n",
    "    \n",
    "    if final_price > 0.9:\n",
    "        return 1  # YES outcome\n",
    "    elif final_price < 0.1:\n",
    "        return 0  # NO outcome\n",
    "    else:\n",
    "        return None  # Ambiguous\n",
    "\n",
    "outcomes = {}\n",
    "for ticker in resolved_tickers:\n",
    "    ticker_df = df[df['ticker'] == ticker].sort_values('timestamp')\n",
    "    outcome = infer_outcome(ticker_df)\n",
    "    if outcome is not None:\n",
    "        outcomes[ticker] = outcome\n",
    "\n",
    "print(f\"Inferred outcomes for {len(outcomes)} markets\")\n",
    "print(f\"YES outcomes: {sum(outcomes.values())}\")\n",
    "print(f\"NO outcomes: {len(outcomes) - sum(outcomes.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Calibration Data\n",
    "\n",
    "For each market snapshot, we need:\n",
    "- Predicted probability (yes_prob)\n",
    "- Actual outcome (0 or 1)\n",
    "\n",
    "We'll use all snapshots from resolved markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build calibration dataset\n",
    "calibration_data = []\n",
    "\n",
    "for ticker, outcome in outcomes.items():\n",
    "    ticker_snapshots = df[df['ticker'] == ticker]\n",
    "    \n",
    "    for _, row in ticker_snapshots.iterrows():\n",
    "        calibration_data.append({\n",
    "            'ticker': ticker,\n",
    "            'timestamp': row['timestamp'],\n",
    "            'predicted_prob': row['yes_prob'],\n",
    "            'actual_outcome': outcome\n",
    "        })\n",
    "\n",
    "calib_df = pd.DataFrame(calibration_data)\n",
    "\n",
    "print(f\"Calibration dataset: {len(calib_df):,} predictions\")\n",
    "print(f\"From {calib_df['ticker'].nunique()} markets\")\n",
    "calib_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability Diagram\n",
    "\n",
    "**The CRITICAL visualization for Phase 1C.**\n",
    "\n",
    "This plot shows:\n",
    "- **X-axis**: Predicted probability (what market says)\n",
    "- **Y-axis**: Actual frequency (what actually happened)\n",
    "- **Perfect calibration**: Points on diagonal line\n",
    "- **Overconfident**: Points below diagonal (predicted > actual)\n",
    "- **Underconfident**: Points above diagonal (predicted < actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(calib_df) > 0:\n",
    "    fig = plot_reliability_diagram(\n",
    "        predicted_probs=calib_df['predicted_prob'],\n",
    "        actual_outcomes=calib_df['actual_outcome'],\n",
    "        n_bins=10,\n",
    "        figsize=(10, 10)\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough resolved markets yet. Let poller run longer.\")\n",
    "    print(\"Need markets to settle (close) before calibration analysis is possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Metrics\n",
    "\n",
    "Quantitative measures of calibration quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_calibration_metrics(predicted_probs, actual_outcomes, n_bins=10):\n",
    "    \"\"\"Calculate calibration quality metrics.\"\"\"\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    \n",
    "    predicted_freq = []\n",
    "    actual_freq = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = (predicted_probs >= bins[i]) & (predicted_probs < bins[i + 1])\n",
    "        if i == n_bins - 1:\n",
    "            mask = mask | (predicted_probs == bins[i + 1])\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            predicted_freq.append(predicted_probs[mask].mean())\n",
    "            actual_freq.append(actual_outcomes[mask].mean())\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    mse = np.mean((np.array(predicted_freq) - np.array(actual_freq)) ** 2)\n",
    "    \n",
    "    # Mean Absolute Error\n",
    "    mae = np.mean(np.abs(np.array(predicted_freq) - np.array(actual_freq)))\n",
    "    \n",
    "    # Brier Score (lower is better)\n",
    "    brier = np.mean((predicted_probs - actual_outcomes) ** 2)\n",
    "    \n",
    "    return {\n",
    "        'calibration_mse': mse,\n",
    "        'calibration_mae': mae,\n",
    "        'brier_score': brier,\n",
    "        'n_predictions': len(predicted_probs)\n",
    "    }\n",
    "\n",
    "if len(calib_df) > 0:\n",
    "    metrics = calculate_calibration_metrics(\n",
    "        calib_df['predicted_prob'].values,\n",
    "        calib_df['actual_outcome'].values\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CALIBRATION QUALITY METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Calibration MSE:      {metrics['calibration_mse']:.4f}\")\n",
    "    print(f\"Calibration MAE:      {metrics['calibration_mae']:.4f}\")\n",
    "    print(f\"Brier Score:          {metrics['brier_score']:.4f}\")\n",
    "    print(f\"Total Predictions:    {metrics['n_predictions']:,}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Interpretation\n",
    "    if metrics['calibration_mse'] < 0.01:\n",
    "        print(\"\\n‚úÖ EXCELLENT calibration (MSE < 0.01)\")\n",
    "    elif metrics['calibration_mse'] < 0.05:\n",
    "        print(\"\\n‚úÖ GOOD calibration (MSE < 0.05)\")\n",
    "    elif metrics['calibration_mse'] < 0.10:\n",
    "        print(\"\\n‚ö†Ô∏è FAIR calibration (MSE < 0.10)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå POOR calibration (MSE >= 0.10)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No calibration data available yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration by Time Period\n",
    "\n",
    "Check if calibration varies by how far from resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(calib_df) > 0:\n",
    "    # Add time-to-resolution for each snapshot\n",
    "    def get_time_to_resolution(ticker, timestamp):\n",
    "        ticker_df = df[df['ticker'] == ticker]\n",
    "        last_time = ticker_df['timestamp'].max()\n",
    "        return (last_time - timestamp).total_seconds() / 3600  # hours\n",
    "    \n",
    "    calib_df['hours_to_resolution'] = calib_df.apply(\n",
    "        lambda row: get_time_to_resolution(row['ticker'], row['timestamp']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group by time buckets\n",
    "    time_buckets = [\n",
    "        (0, 1, 'Last Hour'),\n",
    "        (1, 6, '1-6 Hours'),\n",
    "        (6, 24, '6-24 Hours'),\n",
    "        (24, float('inf'), '24+ Hours')\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nCalibration by Time to Resolution:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for min_h, max_h, label in time_buckets:\n",
    "        mask = (calib_df['hours_to_resolution'] >= min_h) & (calib_df['hours_to_resolution'] < max_h)\n",
    "        subset = calib_df[mask]\n",
    "        \n",
    "        if len(subset) > 10:  # Need minimum data\n",
    "            metrics = calculate_calibration_metrics(\n",
    "                subset['predicted_prob'].values,\n",
    "                subset['actual_outcome'].values\n",
    "            )\n",
    "            print(f\"{label:15} | MSE: {metrics['calibration_mse']:.4f} | N: {len(subset):>5}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough data for time-based analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation & Next Steps\n",
    "\n",
    "### What Good Calibration Means\n",
    "- Markets are efficient at aggregating information\n",
    "- Prices reflect true probabilities\n",
    "- Trading edge comes from timing, not market mispricing\n",
    "\n",
    "### What to Do Next\n",
    "\n",
    "**If calibration is good (MSE < 0.05)**:\n",
    "- ‚úÖ Proceed with strategy development\n",
    "- Focus on timing (mean reversion, momentum)\n",
    "- Risk management is critical (markets are smart)\n",
    "\n",
    "**If calibration is poor (MSE > 0.10)**:\n",
    "- üîç Investigate why:\n",
    "  - Not enough resolved markets?\n",
    "  - Outcome inference incorrect?\n",
    "  - Markets need more time to settle?\n",
    "- Consider focusing on specific market types\n",
    "- May indicate inefficiencies to exploit\n",
    "\n",
    "**Data Requirements**:\n",
    "- Need ‚â•100 predictions from ‚â•10 markets for reliable calibration\n",
    "- Markets must have resolved (settled)\n",
    "- May take 1-7 days depending on market types\n",
    "\n",
    "### Phase 1C Completion\n",
    "Once we have:\n",
    "1. ‚úÖ Reliability diagram (this notebook)\n",
    "2. ‚úÖ Calibration metrics calculated\n",
    "3. ‚úÖ Strategy with Sharpe >0.5 (from 02_strategy_backtest.ipynb)\n",
    "\n",
    "‚Üí **Phase 1C COMPLETE** ‚Üí Proceed to Phase 2 (Real-time monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save calibration results for future reference\n",
    "if len(calib_df) > 0:\n",
    "    calib_df.to_csv('../data/calibration_results.csv', index=False)\n",
    "    print(\"\\n‚úÖ Calibration results saved to data/calibration_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
